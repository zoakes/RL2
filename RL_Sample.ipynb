{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "nan = np.nan\n",
    "\n",
    "#ARRAY FOR TRANSITION PROB\n",
    "P = np.array([ #SHAPE == [s,a,s']\n",
    "    [[.7,.3,0],[1,0,0],[.8,.2,0]], #State 0's Probabilities (of A0 A1 A2)\n",
    "    [[0,1,0],[nan,nan,nan],[0,0,1]],#State 1's Trans Probs\n",
    "    [[nan,nan,nan],[.8,.1,.1],[nan,nan,nan]]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array for RETURNS (Rewards?)\n",
    "R = np.array([ #Shape -- (Hold Reward, Buy Reward, Sell Reward) ?  OR Same [s,a,s']\n",
    "    [[50,0,0],[0,0,0],[0,0,0]],\n",
    "    [[50,0,0],[nan,nan,nan],[0,0,-250]], #THIS is SELL from Stagnant (Hold, Buy, Sell)\n",
    "    [[nan,nan,nan],[200.0,0,0],[nan,nan,nan]]\n",
    "])\n",
    "\n",
    "\n",
    "#Actions (Per State)\n",
    "\n",
    "    #S0,     S1.    S2.  --- from S0, can hold,buy, sell. (From S1, can Hold, Sell) (S2 -> only Buy)\n",
    "A = [[0,1,2],[0,2],[1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109.43230584 103.95749333  84.274035  ]\n",
      " [  5.5402017          -inf   5.83515676]\n",
      " [        -inf 269.30353051         -inf]]\n",
      "\n",
      "Interpreted as OPTIMAL policy in EACH state....\n",
      "\n",
      "EX: If in State 0 -- Options are [109.43230584 103.95749333  84.274035  ]\n",
      " -> best option in state == np.argmax(Q[state]): 0\n",
      "\n",
      "S0 (Bull Mkt): Optimal: 0 --> 109.4323058394244\n",
      "S1 (Flat Mkt): Optimal: 2 --> 5.835156761507875\n",
      "S2 (Bear Mkt): Optimal: 1 --> 269.30353050771623\n",
      "S0: optimal action: 0 --> 109.4323058394244\n",
      "S1: optimal action: 2 --> 5.835156761507875\n",
      "S2: optimal action: 1 --> 269.30353050771623\n"
     ]
    }
   ],
   "source": [
    "#Now run QValue Iteration\n",
    "Q = np.full((3,3),-np.inf)\n",
    "\n",
    "    #IDX,  Value \n",
    "for state, actions in enumerate(A):\n",
    "    Q[state, actions] = 0.0         #Initial value == 0\n",
    "    \n",
    "\n",
    "discount_rate = .95       #DISC of FUT rewards\n",
    "n_iterations = 100        #Batches\n",
    "\n",
    "#N Iterations (to run)\n",
    "for iteration in range(n_iterations):\n",
    "    \n",
    "    Q_prev = Q.copy()       #COPY it! (To reference for each iter)\n",
    "    for s in range(3):      #Loop through STATES\n",
    "        for a in A[s]:      #LOOP through ACTIONS (PER state!)   Actions for State 0, then WHICH action\n",
    "                            #Was T?     \n",
    "                              #Prob      *  Curr Reward + y* MAX Future Reward (by looping tthrouhg all options)\n",
    "            Q[s,a] = np.sum([ P[s,a,sp] * (R[s,a,sp] + discount_rate * np.max(Q_prev[sp])) for sp in range(3)])\n",
    "print(Q)\n",
    "\n",
    "print(f'\\nInterpreted as OPTIMAL policy in EACH state....')\n",
    "\n",
    "print(f'\\nEX: If in State 0 -- Options are {Q[0]}')\n",
    "print(f' -> best option in state == np.argmax(Q[state]): {np.argmax(Q[0])}\\n')\n",
    "print(f'S0 (Bull Mkt): Optimal: {np.argmax(Q[0])} --> {Q[0][np.argmax(Q[0])]}')\n",
    "print(f'S1 (Flat Mkt): Optimal: {np.argmax(Q[1])} --> {Q[1][np.argmax(Q[1])]}')\n",
    "print(f'S2 (Bear Mkt): Optimal: {np.argmax(Q[2])} --> {Q[2][np.argmax(Q[2])]}')\n",
    "\n",
    "\n",
    "for q_per_state in range(3):\n",
    "    state = q_per_state\n",
    "    print(f'S{state}: optimal action: {np.argmax(Q[state])} --> {Q[state][np.argmax(Q[state])]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NEW RL Algo... from SCRATCH'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import math\n",
    "from numpy.random import choice\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import Model Packages for reinforcement learning\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "spy = yf.download('SPY')\n",
    "spy.shape\n",
    "\n",
    "dataset = spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7071.000</td>\n",
       "      <td>7071.000</td>\n",
       "      <td>7071.000</td>\n",
       "      <td>7071.000</td>\n",
       "      <td>7071.000</td>\n",
       "      <td>7.071e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>144.937</td>\n",
       "      <td>145.797</td>\n",
       "      <td>143.978</td>\n",
       "      <td>144.935</td>\n",
       "      <td>119.851</td>\n",
       "      <td>8.451e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73.186</td>\n",
       "      <td>73.507</td>\n",
       "      <td>72.822</td>\n",
       "      <td>73.188</td>\n",
       "      <td>78.638</td>\n",
       "      <td>9.646e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>43.344</td>\n",
       "      <td>43.531</td>\n",
       "      <td>42.812</td>\n",
       "      <td>43.406</td>\n",
       "      <td>25.655</td>\n",
       "      <td>5.200e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>99.970</td>\n",
       "      <td>100.860</td>\n",
       "      <td>98.944</td>\n",
       "      <td>99.944</td>\n",
       "      <td>71.054</td>\n",
       "      <td>7.864e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>127.380</td>\n",
       "      <td>128.180</td>\n",
       "      <td>126.500</td>\n",
       "      <td>127.390</td>\n",
       "      <td>93.667</td>\n",
       "      <td>5.829e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>184.100</td>\n",
       "      <td>184.615</td>\n",
       "      <td>182.980</td>\n",
       "      <td>184.160</td>\n",
       "      <td>160.729</td>\n",
       "      <td>1.207e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>393.960</td>\n",
       "      <td>394.170</td>\n",
       "      <td>391.530</td>\n",
       "      <td>392.640</td>\n",
       "      <td>392.640</td>\n",
       "      <td>8.710e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low     Close  Adj Close     Volume\n",
       "count  7071.000  7071.000  7071.000  7071.000   7071.000  7.071e+03\n",
       "mean    144.937   145.797   143.978   144.935    119.851  8.451e+07\n",
       "std      73.186    73.507    72.822    73.188     78.638  9.646e+07\n",
       "min      43.344    43.531    42.812    43.406     25.655  5.200e+03\n",
       "25%      99.970   100.860    98.944    99.944     71.054  7.864e+06\n",
       "50%     127.380   128.180   126.500   127.390     93.667  5.829e+07\n",
       "75%     184.100   184.615   182.980   184.160    160.729  1.207e+08\n",
       "max     393.960   394.170   391.530   392.640    392.640  8.710e+08"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_option('precision', 3)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb957196fd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Close.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-29</th>\n",
       "      <td>43.969</td>\n",
       "      <td>43.969</td>\n",
       "      <td>43.750</td>\n",
       "      <td>43.938</td>\n",
       "      <td>25.969</td>\n",
       "      <td>1003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-01</th>\n",
       "      <td>43.969</td>\n",
       "      <td>44.250</td>\n",
       "      <td>43.969</td>\n",
       "      <td>44.250</td>\n",
       "      <td>26.154</td>\n",
       "      <td>480500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close  Adj Close   Volume\n",
       "Date                                                          \n",
       "1993-01-29  43.969  43.969  43.750  43.938     25.969  1003200\n",
       "1993-02-01  43.969  44.250  43.969  44.250     26.154   480500"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fill the missing values with the last value available in the dataset. \n",
    "dataset=dataset.fillna(method='ffill')\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list(dataset[\"Close\"])\n",
    "X=[float(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "#In case the data is not dependent on the time series, then train and test split should be done based on sequential sample\n",
    "#This can be done by selecting an arbitrary split point in the ordered list of observations and creating two new datasets.\n",
    "train_size = int(len(X) * (1-validation_size))\n",
    "X_train, X_test = X[0:train_size], X[train_size:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tatsath/fin-ml/blob/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%201%20-%20Reinforcement%20Learning%20based%20Trading%20Strategy/ReinforcementLearningBasedTradingStrategy.ipynb\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, is_eval=False, model_name=''):\n",
    "        #State size depends and is equal to the the window size, n previous days\n",
    "        self.state_size = state_size\n",
    "        self.action_size = 3 #Hold, Buy, Sell\n",
    "        self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = load_model(model_name) if is_eval else self._model()\n",
    "        \n",
    "    #Deep Q Learning model- returns the q-value when given state as input \n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        #Input Layer\n",
    "        model.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
    "        #Hidden Layers\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(units=8, activation=\"relu\"))\n",
    "        #Output Layer \n",
    "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
    "        return model\n",
    "    \n",
    "    #Return the action on the value function\n",
    "    #With probability (1-$\\epsilon$) choose the action which has the highest Q-value.\n",
    "    #With probability ($\\epsilon$) choose any action at random.\n",
    "    #Intitially high epsilon-more random, later less\n",
    "    \n",
    "    #The trained agents were evaluated by different initial random condition\n",
    "    #and an e-greedy policy with epsilon 0.05. \n",
    "    #This procedure is adopted to minimize the possibility of overfitting during evaluation.\n",
    "    \n",
    "    def act(self, state):\n",
    "        #If it is test and self.epsilon is still very high, once the epsilon become low, there are no random\n",
    "        #actions suggested.\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "            #RANDOM hit -- randomly choose bw 0 - 2\n",
    "            return random.randrange(self.action_size)\n",
    "        #Otherwise --> PREDICT!\n",
    "        options = self.model.predict(state)\n",
    "        return np.argmax(options[0]) #Should this be options[state] ? \n",
    "    \n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        l = len(self.memory) #1k\n",
    "        #Record mini batch (start at end of memory, subtract batch size, up to end of mem)\n",
    "        for i in range(l - batch_size + 1, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        \n",
    "        # the memory during the training phase. \n",
    "        #      St,     At,     Rt,       St+1,  Quit? \n",
    "        for state, action, reward, next_state, done in mini_batch:\n",
    "            target = reward      # reward or Q at time t  \n",
    "            \n",
    "            #update the Q table based on Q table equation (IF not done)\n",
    "            if not done:\n",
    "                #Using BELLMAN equation\n",
    "                pred_next = self.model.predict(next_state)[0] #WHY this 0? BC of ARRAY?\n",
    "                target = reward + self.gamma * np.amax(pred_next)\n",
    "            \n",
    "            # Q-value of the CURRENT state from the table \n",
    "            target_f = self.model.predict(state)\n",
    "            # Update Q Table \n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            #Train\n",
    "            #train and fit the model where state is X and target_f is Y, where the target is updated.\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        #DECAY epsilon (Optional) -> Reduces epsilon each time it's ran (UP to a min value)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper Functions'''\n",
    "import math\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "    return (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# # returns the vector containing stock data from a fixed file \n",
    "# def getStockData(key):\n",
    "#     vec = []\n",
    "#     lines = open(\"data/\" + key + \".csv\", \"r\").read().splitlines()\n",
    "\n",
    "#     for line in lines[1:]:\n",
    "#         vec.append(float(line.split(\",\")[4])) #Only Close column\n",
    "\n",
    "#     return vec\n",
    "\n",
    "\n",
    "def sigmoid(p):\n",
    "    return 1 / (1 + math.exp(-p))\n",
    "\n",
    "# returns an an n-day state representation ending at time t\n",
    "\n",
    "def getState(data, t, n):    \n",
    "    d = t - n + 1\n",
    "    block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # pad with t0\n",
    "    #block is which is the for [1283.27002, 1283.27002]\n",
    "    res = []\n",
    "    for i in range(n - 1):\n",
    "        res.append(sigmoid(block[i + 1] - block[i]))\n",
    "    return np.array([res])\n",
    "\n",
    "# Plots the behavior of the output\n",
    "def plot_behavior(data_input, states_buy, states_sell, profit):\n",
    "    fig = plt.figure(figsize = (15,5))\n",
    "    plt.plot(data_input, color='r', lw=2.)\n",
    "    plt.plot(data_input, '^', markersize=10, color='m', label = 'Buying signal', markevery = states_buy)\n",
    "    plt.plot(data_input, 'v', markersize=10, color='k', label = 'Selling signal', markevery = states_sell)\n",
    "    plt.title('Total gains: %f'%(profit))\n",
    "    plt.legend()\n",
    "    #plt.savefig('output/'+name+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getState(data, t, n):   \n",
    "#     #START at time - n (+ 1) -- get data window from n iter in batch to time.\n",
    "#     d = t - n + 1\n",
    "#     block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # pad with t0\n",
    "#     #block is which is the for [1283.27002, 1283.27002]\n",
    "#     res = []\n",
    "#     for i in range(n - 1):\n",
    "#         res.append(sigmoid(block[i + 1] - block[i]))\n",
    "#     return np.array([res])\n",
    "\n",
    "\n",
    "# getState(X_train,0,3)\n",
    "\n",
    "\n",
    "# data = X_train\n",
    "# d = 0 - 1 + 1\n",
    "# t = 0\n",
    "# n = 1\n",
    "# block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # pad with t0\n",
    "# block\n",
    "\n",
    "\n",
    "# #These are exactly the same  (To avoid -index)\n",
    "# print(data[d:t+1] if d >= 0 else 0)\n",
    "# print(-d * [data[0]] + data[0:t + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running episode 0/10\n",
      "Buy: $43.94\n",
      "Sell: $44.25 | Profit: $0.31\n",
      "Buy: $44.97\n",
      "Buy: $44.97\n",
      "Sell: $44.94 | Profit: -$0.03\n",
      "Sell: $43.47 | Profit: -$1.50\n",
      "Buy: $43.44\n",
      "Buy: $43.41\n",
      "Sell: $43.72 | Profit: $0.28\n",
      "Sell: $43.69 | Profit: $0.28\n",
      "Buy: $44.34\n",
      "Sell: $44.41 | Profit: $0.06\n",
      "Buy: $45.12\n",
      "Buy: $44.75\n",
      "Buy: $45.59\n",
      "Sell: $45.31 | Profit: $0.19\n",
      "Buy: $45.03\n",
      "Sell: $45.03 | Profit: $0.28\n",
      "Buy: $44.88\n",
      "Buy: $45.16\n",
      "Buy: $44.91\n",
      "Sell: $45.09 | Profit: -$0.50\n",
      "Buy: $45.22\n",
      "Sell: $45.19 | Profit: $0.16\n",
      "Sell: $44.31 | Profit: -$0.56\n",
      "Sell: $44.19 | Profit: -$0.97\n",
      "Buy: $44.28\n",
      "Buy: $44.91\n",
      "Buy: $45.00\n",
      "Buy: $44.75\n",
      "Buy: $44.53\n",
      "Buy: $44.50\n",
      "Buy: $43.88\n",
      "Sell: $43.78 | Profit: -$1.12\n",
      "Sell: $43.97 | Profit: -$1.25\n",
      "Buy: $44.03\n",
      "Sell: $44.31 | Profit: $0.03\n",
      "Sell: $44.47 | Profit: -$0.44\n",
      "Buy: $44.59\n",
      "Sell: $44.44 | Profit: -$0.56\n",
      "Sell: $44.34 | Profit: -$0.41\n",
      "Sell: $44.62 | Profit: $0.09\n",
      "Sell: $44.56 | Profit: $0.06\n",
      "Sell: $44.00 | Profit: $0.12\n",
      "Sell: $44.12 | Profit: $0.09\n",
      "Sell: $45.16 | Profit: $0.56\n",
      "Buy: $44.94\n",
      "Sell: $45.03 | Profit: $0.09\n",
      "Buy: $45.59\n",
      "Sell: $45.59 | Profit: $0.00\n",
      "Buy: $44.94\n",
      "Sell: $45.03 | Profit: $0.09\n",
      "Buy: $44.22\n",
      "Sell: $44.78 | Profit: $0.56\n",
      "Buy: $44.91\n",
      "Buy: $45.06\n",
      "Buy: $44.75\n",
      "Sell: $44.72 | Profit: -$0.19\n",
      "Sell: $44.81 | Profit: -$0.25\n",
      "Buy: $44.50\n"
     ]
    }
   ],
   "source": [
    "## RUN the model...\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "window_size = 1\n",
    "agent = Agent(window_size)\n",
    "#In this step we feed the closing value of the stock price \n",
    "data = X_train\n",
    "l = len(data) - 1\n",
    "#\n",
    "batch_size = 32\n",
    "#An episode represents a complete pass over the data.\n",
    "episode_count = 10\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "    print(\"Running episode \" + str(e) + \"/\" + str(episode_count))\n",
    "    state = getState(data, 0, window_size + 1)\n",
    "    #set_trace()\n",
    "    total_profit = 0\n",
    "    agent.inventory = []\n",
    "    states_sell = []\n",
    "    states_buy = []\n",
    "    for t in range(l):\n",
    "        action = agent.act(state)    \n",
    "        # sit\n",
    "        next_state = getState(data, t + 1, window_size + 1)\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1: # buy\n",
    "            agent.inventory.append(data[t])\n",
    "            states_buy.append(t)\n",
    "            print(\"Buy: \" + formatPrice(data[t]))\n",
    "\n",
    "        elif action == 2 and len(agent.inventory) > 0: # sell\n",
    "            bought_price = agent.inventory.pop(0)      \n",
    "            reward = max(data[t] - bought_price, 0)\n",
    "            total_profit += data[t] - bought_price\n",
    "            states_sell.append(t)\n",
    "            print(\"Sell: \" + formatPrice(data[t]) + \" | Profit: \" + formatPrice(data[t] - bought_price))\n",
    "\n",
    "        done = True if t == l - 1 else False\n",
    "        #appends the details of the state action etc in the memory, which is used further by the exeReply function\n",
    "        agent.memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "            print(\"--------------------------------\")\n",
    "            #set_trace()\n",
    "            #pd.DataFrame(np.array(agent.memory)).to_csv(\"Agent\"+str(e)+\".csv\")\n",
    "            #Chart to show how the model performs with the stock goin up and down for each \n",
    "            plot_behavior(data,states_buy, states_sell, total_profit)\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)    \n",
    "            \n",
    "\n",
    "    if e % 2 == 0:\n",
    "        agent.model.save(\"model_ep\" + str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
